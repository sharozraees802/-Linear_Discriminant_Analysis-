{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4a1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6868c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ✅ Phase 2 DR method\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# ✅ Same SVM choice you used in Phase 1 (LinearSVC)\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79845d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_ROOT = \"Datasets\"  # <-- if you use absolute path in phase1, keep that here too\n",
    "RESULTS_XLSX = \"/Users/classroomservices/Desktop/Winter/Machine Learning/Project/Code/Datasets/Results.xlsx\"\n",
    "\n",
    "# ✅ For Phase 2 output file\n",
    "OUT_PHASE2 = \"Results_AFTER_filled.xlsx\"\n",
    "\n",
    "LABEL_COL = \"Label\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# REQUIRED outer folds\n",
    "OUTER_FOLDS_DEFAULT = 10\n",
    "\n",
    "# Inner CV folds (same as Phase 1)\n",
    "INNER_FOLDS = 3\n",
    "inner_cv = StratifiedKFold(n_splits=INNER_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# n_jobs stability for nested CV on Mac\n",
    "N_JOBS = 1\n",
    "\n",
    "# ✅ Email: You can use RandomizedSearchCV for SVM (must mention in report)\n",
    "N_ITER_SVM = 10   # 8-15 typical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86928b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_one_dataset(dataset_id: int):\n",
    "    \"\"\"\n",
    "    Loads Datasets/<id>/train.csv + test.csv and combines them.\n",
    "    \"\"\"\n",
    "    train_path = os.path.join(DATA_ROOT, str(dataset_id), \"train.csv\")\n",
    "    test_path  = os.path.join(DATA_ROOT, str(dataset_id), \"test.csv\")\n",
    "\n",
    "    df = pd.concat([pd.read_csv(train_path), pd.read_csv(test_path)], ignore_index=True)\n",
    "\n",
    "    if LABEL_COL not in df.columns:\n",
    "        raise ValueError(f\"'{LABEL_COL}' not found in dataset {dataset_id}\")\n",
    "\n",
    "    X = df.drop(columns=[LABEL_COL])\n",
    "    y = pd.Series(pd.factorize(df[LABEL_COL])[0], index=df.index)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18d4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_grid(clf_name: str):\n",
    "    \"\"\"\n",
    "    Same models and grids as your Phase 1 baseline code.\n",
    "    \"\"\"\n",
    "    if clf_name == \"SVM\":\n",
    "        model = LinearSVC(dual=\"auto\", max_iter=100000, tol=2e-3, random_state=RANDOM_STATE)\n",
    "        grid = {\"clf__C\": [0.01, 0.1, 1, 10]}\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"KNN\":\n",
    "        model = KNeighborsClassifier()\n",
    "        grid = {\n",
    "            \"clf__n_neighbors\": [3, 5, 7, 9, 11],\n",
    "            \"clf__weights\": [\"uniform\", \"distance\"]\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"DT\":\n",
    "        model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "        grid = {\n",
    "            \"clf__max_depth\": [None, 5, 10, 20],\n",
    "            \"clf__min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"RF\":\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "        grid = {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__max_depth\": [None, 10, 20]\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"MLP\":\n",
    "        model = MLPClassifier(\n",
    "            max_iter=300,\n",
    "            early_stopping=True,\n",
    "            n_iter_no_change=10,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        grid = {\n",
    "            \"clf__hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "            \"clf__alpha\": [1e-4, 1e-3, 1e-2]\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    raise ValueError(\"Unknown classifier: \" + clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a018aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_params(best_params: dict, prefix: str):\n",
    "    parts = []\n",
    "    for k, v in best_params.items():\n",
    "        if k.startswith(prefix):\n",
    "            parts.append(f\"{k.replace(prefix,'')}={v}\")\n",
    "    return \"; \".join(parts)\n",
    "\n",
    "def get_n_components(best_params: dict):\n",
    "    return best_params.get(\"lda__n_components\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccfe2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lda_one_classifier(dataset_id: int, clf_name: str):\n",
    "    \"\"\"\n",
    "    PHASE 2 (After FS/DR): LDA + classifier\n",
    "\n",
    "    Pipeline:\n",
    "      Imputer -> Scaler -> LDA -> Classifier\n",
    "\n",
    "    Tuning:\n",
    "      - SVM uses RandomizedSearchCV (email allowed; mention in report)\n",
    "      - Others use GridSearchCV\n",
    "    \"\"\"\n",
    "    X, y = load_one_dataset(dataset_id)\n",
    "    model, clf_grid = get_model_and_grid(clf_name)\n",
    "\n",
    "    # LDA max components = (#classes - 1)\n",
    "    n_classes = len(np.unique(y))\n",
    "    max_comp = max(1, n_classes - 1)\n",
    "\n",
    "    # Outer CV always 10 folds\n",
    "    outer_cv_local = StratifiedKFold(n_splits=OUTER_FOLDS_DEFAULT, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    fold_rows = []\n",
    "    print(f\"\\n✅ Phase 2 (LDA) | Data {dataset_id} | {clf_name} | max_comp={max_comp}\")\n",
    "\n",
    "    for fold_idx, (tr_idx, va_idx) in enumerate(outer_cv_local.split(X, y), start=1):\n",
    "        print(f\"➡️ {clf_name} Fold {fold_idx}/10 ...\")\n",
    "\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        # ✅ Phase 2 pipeline: add LDA\n",
    "        pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"lda\", LinearDiscriminantAnalysis(solver=\"svd\")),\n",
    "            (\"clf\", model)\n",
    "        ])\n",
    "\n",
    "        # Combine classifier grid + LDA grid\n",
    "        param_grid = dict(clf_grid)\n",
    "        param_grid.update({\n",
    "            \"lda__n_components\": list(range(1, max_comp + 1))\n",
    "        })\n",
    "\n",
    "        # ✅ Email rule: SVM may use RandomizedSearchCV\n",
    "        if clf_name == \"SVM\":\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=pipe,\n",
    "                param_distributions=param_grid,\n",
    "                n_iter=N_ITER_SVM,\n",
    "                scoring=\"f1_macro\",\n",
    "                cv=inner_cv,\n",
    "                n_jobs=N_JOBS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                refit=True\n",
    "            )\n",
    "        else:\n",
    "            search = GridSearchCV(\n",
    "                estimator=pipe,\n",
    "                param_grid=param_grid,\n",
    "                scoring=\"f1_macro\",\n",
    "                cv=inner_cv,\n",
    "                n_jobs=N_JOBS,\n",
    "                refit=True\n",
    "            )\n",
    "\n",
    "        t0 = time.time()\n",
    "        search.fit(X_tr, y_tr)\n",
    "        fit_t = time.time() - t0\n",
    "\n",
    "        y_pred = search.predict(X_va)\n",
    "        acc = accuracy_score(y_va, y_pred)\n",
    "        f1m = f1_score(y_va, y_pred, average=\"macro\")\n",
    "\n",
    "        best = search.best_params_\n",
    "\n",
    "        print(f\"✅ Done | Acc={acc:.4f} F1={f1m:.4f} | fit={fit_t:.1f}s\")\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"fold\": fold_idx,\n",
    "            \"accuracy\": float(acc),\n",
    "            \"f1_macro\": float(f1m),\n",
    "            \"lda_params_str\": format_params(best, \"lda__\"),\n",
    "            \"clf_params_str\": format_params(best, \"clf__\"),\n",
    "            \"n_components\": get_n_components(best),\n",
    "        })\n",
    "\n",
    "    return fold_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0141686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_block_start_row(dataset_id: int) -> int:\n",
    "    return 1 + (dataset_id - 1) * 12\n",
    "\n",
    "def fold_row(dataset_id: int, fold_idx: int) -> int:\n",
    "    return dataset_block_start_row(dataset_id) + 2 + (fold_idx - 1)\n",
    "\n",
    "def write_after_sheet(ws_after, dataset_id: int, results: dict):\n",
    "    \"\"\"\n",
    "    Writes into 'After FS-DR' sheet.\n",
    "\n",
    "    Template columns:\n",
    "      B..K : Acc/F1 for SVM,KNN,DT,RF,MLP\n",
    "      L    : No. Selected Features (we store all classifiers as one string)\n",
    "      M    : Features Name (N/A for LDA)\n",
    "      N..R : FS/DS Parameters for each classifier\n",
    "    \"\"\"\n",
    "    clfs = [\"SVM\", \"KNN\", \"DT\", \"RF\", \"MLP\"]\n",
    "\n",
    "    for f in range(1, 11):\n",
    "        r = fold_row(dataset_id, f)\n",
    "\n",
    "        # B..K metrics\n",
    "        col = 2\n",
    "        for clf in clfs:\n",
    "            row = results[clf][f-1]\n",
    "            ws_after.cell(row=r, column=col).value   = round(row[\"accuracy\"], 4)\n",
    "            ws_after.cell(row=r, column=col+1).value = round(row[\"f1_macro\"], 4)\n",
    "            col += 2\n",
    "\n",
    "        # L: No. Selected Features (LDA components)\n",
    "        comps = [f\"{clf}={results[clf][f-1]['n_components']}\" for clf in clfs]\n",
    "        ws_after.cell(row=r, column=12).value = \";\".join(comps)\n",
    "\n",
    "        # M: Features Name (not applicable for LDA)\n",
    "        ws_after.cell(row=r, column=13).value = \"N/A (LDA)\"\n",
    "\n",
    "        # N..R: FS/DS parameters for each classifier\n",
    "        c = 14\n",
    "        for clf in clfs:\n",
    "            row = results[clf][f-1]\n",
    "            ws_after.cell(row=r, column=c).value = f\"LDA({row['lda_params_str']}); {row['clf_params_str']}\"\n",
    "            c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d97d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ PHASE 2 (LDA) | DATA 1 ================\n",
      "\n",
      "✅ Phase 2 (LDA) | Data 1 | SVM | max_comp=3\n",
      "➡️ SVM Fold 1/10 ...\n",
      "✅ Done | Acc=0.9139 F1=0.6367 | fit=0.4s\n",
      "➡️ SVM Fold 2/10 ...\n",
      "✅ Done | Acc=0.9085 F1=0.6294 | fit=0.4s\n",
      "➡️ SVM Fold 3/10 ...\n",
      "✅ Done | Acc=0.9241 F1=0.6304 | fit=0.4s\n",
      "➡️ SVM Fold 4/10 ...\n",
      "✅ Done | Acc=0.9225 F1=0.6387 | fit=0.4s\n",
      "➡️ SVM Fold 5/10 ...\n",
      "✅ Done | Acc=0.9218 F1=0.6258 | fit=0.4s\n",
      "➡️ SVM Fold 6/10 ...\n",
      "✅ Done | Acc=0.9139 F1=0.6100 | fit=0.4s\n",
      "➡️ SVM Fold 7/10 ...\n",
      "✅ Done | Acc=0.9155 F1=0.6376 | fit=0.4s\n",
      "➡️ SVM Fold 8/10 ...\n",
      "✅ Done | Acc=0.9218 F1=0.6329 | fit=0.4s\n",
      "➡️ SVM Fold 9/10 ...\n",
      "✅ Done | Acc=0.9115 F1=0.6189 | fit=0.4s\n",
      "➡️ SVM Fold 10/10 ...\n",
      "✅ Done | Acc=0.9107 F1=0.6271 | fit=0.4s\n",
      "\n",
      "✅ Phase 2 (LDA) | Data 1 | KNN | max_comp=3\n",
      "➡️ KNN Fold 1/10 ...\n",
      "✅ Done | Acc=0.9836 F1=0.7282 | fit=1.3s\n",
      "➡️ KNN Fold 2/10 ...\n",
      "✅ Done | Acc=0.9797 F1=0.7147 | fit=1.3s\n",
      "➡️ KNN Fold 3/10 ...\n",
      "✅ Done | Acc=0.9781 F1=0.7083 | fit=1.3s\n",
      "➡️ KNN Fold 4/10 ...\n",
      "✅ Done | Acc=0.9781 F1=0.7141 | fit=1.3s\n",
      "➡️ KNN Fold 5/10 ...\n",
      "✅ Done | Acc=0.9789 F1=0.7066 | fit=1.3s\n",
      "➡️ KNN Fold 6/10 ...\n",
      "✅ Done | Acc=0.9765 F1=0.9607 | fit=1.3s\n",
      "➡️ KNN Fold 7/10 ...\n",
      "✅ Done | Acc=0.9851 F1=0.7294 | fit=1.3s\n",
      "➡️ KNN Fold 8/10 ...\n",
      "✅ Done | Acc=0.9844 F1=0.9716 | fit=1.3s\n",
      "➡️ KNN Fold 9/10 ...\n",
      "✅ Done | Acc=0.9789 F1=0.7234 | fit=1.3s\n",
      "➡️ KNN Fold 10/10 ...\n",
      "✅ Done | Acc=0.9757 F1=0.7147 | fit=1.3s\n",
      "\n",
      "✅ Phase 2 (LDA) | Data 1 | DT | max_comp=3\n",
      "➡️ DT Fold 1/10 ...\n",
      "✅ Done | Acc=0.9648 F1=0.6923 | fit=2.2s\n",
      "➡️ DT Fold 2/10 ...\n",
      "✅ Done | Acc=0.9585 F1=0.6891 | fit=2.2s\n",
      "➡️ DT Fold 3/10 ...\n",
      "✅ Done | Acc=0.9632 F1=0.6882 | fit=2.2s\n",
      "➡️ DT Fold 4/10 ...\n",
      "✅ Done | Acc=0.9609 F1=0.6981 | fit=2.2s\n",
      "➡️ DT Fold 5/10 ...\n",
      "✅ Done | Acc=0.9664 F1=0.6973 | fit=2.2s\n",
      "➡️ DT Fold 6/10 ...\n",
      "✅ Done | Acc=0.9531 F1=0.8467 | fit=2.2s\n",
      "➡️ DT Fold 7/10 ...\n",
      "✅ Done | Acc=0.9640 F1=0.7044 | fit=2.2s\n",
      "➡️ DT Fold 8/10 ...\n",
      "✅ Done | Acc=0.9695 F1=0.8502 | fit=2.2s\n",
      "➡️ DT Fold 9/10 ...\n",
      "✅ Done | Acc=0.9585 F1=0.6952 | fit=2.2s\n",
      "➡️ DT Fold 10/10 ...\n",
      "✅ Done | Acc=0.9624 F1=0.6826 | fit=2.2s\n",
      "\n",
      "✅ Phase 2 (LDA) | Data 1 | RF | max_comp=3\n",
      "➡️ RF Fold 1/10 ...\n",
      "✅ Done | Acc=0.9773 F1=0.7147 | fit=35.6s\n",
      "➡️ RF Fold 2/10 ...\n",
      "✅ Done | Acc=0.9750 F1=0.7097 | fit=35.9s\n",
      "➡️ RF Fold 3/10 ...\n",
      "✅ Done | Acc=0.9750 F1=0.7023 | fit=35.5s\n",
      "➡️ RF Fold 4/10 ...\n",
      "✅ Done | Acc=0.9812 F1=0.7196 | fit=36.1s\n",
      "➡️ RF Fold 5/10 ...\n",
      "✅ Done | Acc=0.9836 F1=0.7142 | fit=36.2s\n",
      "➡️ RF Fold 6/10 ...\n",
      "✅ Done | Acc=0.9562 F1=0.9332 | fit=35.2s\n",
      "➡️ RF Fold 7/10 ...\n",
      "✅ Done | Acc=0.9765 F1=0.7179 | fit=35.7s\n",
      "➡️ RF Fold 8/10 ...\n"
     ]
    }
   ],
   "source": [
    "wb = openpyxl.load_workbook(RESULTS_XLSX)\n",
    "ws_after = wb[\"After FS-DR\"]\n",
    "\n",
    "clfs = [\"SVM\", \"KNN\", \"DT\", \"RF\", \"MLP\"]\n",
    "\n",
    "for dataset_id in range(1, 17):\n",
    "    print(f\"\\n================ PHASE 2 (LDA) | DATA {dataset_id} ================\")\n",
    "\n",
    "    results = {}\n",
    "    for clf in clfs:\n",
    "        results[clf] = run_lda_one_classifier(dataset_id, clf)\n",
    "\n",
    "    write_after_sheet(ws_after, dataset_id, results)\n",
    "\n",
    "    wb.save(OUT_PHASE2)\n",
    "    print(\"✅ Saved checkpoint:\", OUT_PHASE2)\n",
    "\n",
    "print(\"\\n✅ Phase 2 complete:\", OUT_PHASE2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
