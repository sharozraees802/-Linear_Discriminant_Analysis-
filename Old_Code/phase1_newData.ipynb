{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85b6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Imports\n",
    "# =========================\n",
    "\n",
    "import os                    # work with folders/paths\n",
    "import numpy as np           # math/statistics\n",
    "import pandas as pd          # reading CSV files\n",
    "\n",
    "# Cross-validation + tuning\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "# Pipeline = prevents data leakage (everything happens inside CV folds)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preprocessing inside folds\n",
    "from sklearn.impute import SimpleImputer     # handle missing values\n",
    "from sklearn.preprocessing import StandardScaler  # scale features\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# The 5 classifiers (Phase 1 baseline)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509bf1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Global settings\n",
    "# =========================\n",
    "\n",
    "DATA_ROOT = \"Datasets\"   # folder that contains 1..16 subfolders\n",
    "LABEL_COL = \"Label\"      # label column name in your CSV\n",
    "RANDOM_STATE = 42        # makes results reproducible\n",
    "\n",
    "# Outer CV = 10 folds (matches Excel Fold1..Fold10)\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Inner CV = used only for hyperparameter tuning (nested CV)\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8176596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Function 1: Load ONE dataset\n",
    "# =========================\n",
    "\n",
    "def load_one_dataset(dataset_id: int):\n",
    "    \"\"\"\n",
    "    Reads:\n",
    "      Datasets/<dataset_id>/train.csv\n",
    "      Datasets/<dataset_id>/test.csv\n",
    "\n",
    "    Then combines them (train+test) and returns:\n",
    "      X = features\n",
    "      y = labels\n",
    "\n",
    "    Why combine train+test?\n",
    "    Some datasets have too few samples per class in train.csv alone,\n",
    "    making 10-fold Stratified CV impossible. Combining fixes that.\n",
    "    \"\"\"\n",
    "\n",
    "    train_path = os.path.join(DATA_ROOT, str(dataset_id), \"train.csv\")\n",
    "    test_path  = os.path.join(DATA_ROOT, str(dataset_id), \"test.csv\")\n",
    "\n",
    "    # Read both csv files\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df  = pd.read_csv(test_path)\n",
    "\n",
    "    # Combine them into one full dataset\n",
    "    df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    # Split features and label\n",
    "    if LABEL_COL not in df.columns:\n",
    "        raise ValueError(f\"Label column '{LABEL_COL}' not found in dataset {dataset_id}.\")\n",
    "\n",
    "    X = df.drop(columns=[LABEL_COL])\n",
    "    y = df[LABEL_COL]\n",
    "\n",
    "    # Ensure labels are numeric for sklearn (safe even if already numeric)\n",
    "    y = pd.Series(pd.factorize(y)[0], index=df.index)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a892a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Function 2: Choose ONE classifier and its hyperparameter grid\n",
    "# =========================\n",
    "\n",
    "def get_model_and_grid(clf_name: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      model, param_grid\n",
    "    for the classifier name you pass in.\n",
    "    \"\"\"\n",
    "\n",
    "    if clf_name == \"SVM\":\n",
    "        model = SVC()\n",
    "        grid = {\n",
    "            \"clf__C\": [0.1, 1, 10],\n",
    "            \"clf__kernel\": [\"rbf\", \"linear\"],\n",
    "            \"clf__gamma\": [\"scale\", \"auto\"],\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"KNN\":\n",
    "        model = KNeighborsClassifier()\n",
    "        grid = {\n",
    "            \"clf__n_neighbors\": [3, 5, 7, 9, 11],\n",
    "            \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"DT\":\n",
    "        model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "        grid = {\n",
    "            \"clf__max_depth\": [None, 5, 10, 20],\n",
    "            \"clf__min_samples_split\": [2, 5, 10],\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"RF\":\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "        grid = {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__max_depth\": [None, 10, 20],\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    if clf_name == \"MLP\":\n",
    "        model = MLPClassifier(max_iter=500, random_state=RANDOM_STATE)\n",
    "        grid = {\n",
    "            \"clf__hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "            \"clf__alpha\": [1e-4, 1e-3, 1e-2],\n",
    "            \"clf__learning_rate_init\": [1e-3, 1e-2],\n",
    "        }\n",
    "        return model, grid\n",
    "\n",
    "    raise ValueError(f\"Unknown classifier name: {clf_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "902d65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Helper: Convert best_params dict to a short string\n",
    "# =========================\n",
    "\n",
    "def best_params_to_string(best_params: dict) -> str:\n",
    "    \"\"\"\n",
    "    Example:\n",
    "      {\"clf__C\":10, \"clf__kernel\":\"rbf\"} -> \"C=10; kernel=rbf\"\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for k, v in best_params.items():\n",
    "        parts.append(f\"{k.replace('clf__','')}={v}\")\n",
    "    return \"; \".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a15dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6) MAIN function: Run ONE classifier (Phase 1 baseline)\n",
    "# =========================\n",
    "\n",
    "def run_phase1_one_classifier(dataset_id: int, clf_name: str):\n",
    "    \"\"\"\n",
    "    PHASE 1 BASELINE:\n",
    "      - No feature selection\n",
    "      - No dimensionality reduction\n",
    "\n",
    "    For ONE dataset and ONE classifier:\n",
    "      Outer loop: 10-fold Stratified CV\n",
    "      Inner loop: GridSearchCV (tuning) on training fold only\n",
    "\n",
    "    Prints progress so you always know what is running.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Step A: Load data for ONE dataset ---\n",
    "    X, y = load_one_dataset(dataset_id)\n",
    "\n",
    "    # --- Step B: Get the chosen model and hyperparameter grid ---\n",
    "    model, grid = get_model_and_grid(clf_name)\n",
    "\n",
    "    print(\"\\n====================================================\")\n",
    "    print(f\"‚úÖ START | DATASET {dataset_id} | CLASSIFIER = {clf_name}\")\n",
    "    print(\"Phase 1 (Baseline): Imputer -> Scaler -> Classifier\")\n",
    "    print(\"====================================================\")\n",
    "\n",
    "    fold_rows = []  # store fold results here\n",
    "\n",
    "    # --- Step C: Outer CV loop (Fold 1..10) ---\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "\n",
    "        print(f\"\\n‚û°Ô∏è  Now running: {clf_name} | Outer Fold {fold_idx}/10\")\n",
    "\n",
    "        # Split into training fold and validation fold\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # --- Step D: Create pipeline (preprocessing inside folds) ---\n",
    "        # IMPORTANT: This prevents leakage.\n",
    "        # imputer/scaler are fitted ONLY on X_train for each fold.\n",
    "        pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", model),\n",
    "        ])\n",
    "\n",
    "        # --- Step E: Hyperparameter tuning (inner CV only on training fold) ---\n",
    "        gs = GridSearchCV(\n",
    "            estimator=pipe,\n",
    "            param_grid=grid,\n",
    "            scoring=\"f1_macro\",   # macro-F1 (required for multi-class)\n",
    "            cv=inner_cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        )\n",
    "\n",
    "        # Fit ONLY using training fold\n",
    "        gs.fit(X_train, y_train)\n",
    "\n",
    "        # --- Step F: Evaluate on validation fold ---\n",
    "        y_pred = gs.predict(X_val)\n",
    "\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        f1m = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "        print(f\"‚úÖ Fold {fold_idx} DONE | Acc={acc:.4f} | Macro-F1={f1m:.4f}\")\n",
    "        print(f\"‚≠ê Best params: {best_params_to_string(gs.best_params_)}\")\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"fold\": fold_idx,\n",
    "            \"accuracy\": float(acc),\n",
    "            \"f1_macro\": float(f1m),\n",
    "            \"best_params_str\": best_params_to_string(gs.best_params_)\n",
    "        })\n",
    "\n",
    "    # --- Step G: Summary across 10 folds ---\n",
    "    accs = [r[\"accuracy\"] for r in fold_rows]\n",
    "    f1s  = [r[\"f1_macro\"] for r in fold_rows]\n",
    "\n",
    "    print(\"\\n---------------- SUMMARY ----------------\")\n",
    "    print(f\"‚úÖ FINISHED {clf_name} | DATASET {dataset_id}\")\n",
    "    print(f\"Accuracy: {np.mean(accs):.4f} ¬± {np.std(accs, ddof=1):.4f}\")\n",
    "    print(f\"Macro-F1: {np.mean(f1s):.4f} ¬± {np.std(f1s, ddof=1):.4f}\")\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    return fold_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccce1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üîÅ Moving to next classifier: SVM\n",
      "\n",
      "====================================================\n",
      "‚úÖ START | DATASET 1 | CLASSIFIER = SVM\n",
      "Phase 1 (Baseline): Imputer -> Scaler -> Classifier\n",
      "====================================================\n",
      "\n",
      "‚û°Ô∏è  Now running: SVM | Outer Fold 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m clf_name \u001b[38;5;129;01min\u001b[39;00m classifiers:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîÅ Moving to next classifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     phase1_results_data1[clf_name] = \u001b[43mrun_phase1_one_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ ALL classifiers completed for this dataset.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrun_phase1_one_classifier\u001b[39m\u001b[34m(dataset_id, clf_name)\u001b[39m\n\u001b[32m     50\u001b[39m gs = GridSearchCV(\n\u001b[32m     51\u001b[39m     estimator=pipe,\n\u001b[32m     52\u001b[39m     param_grid=grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     refit=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     57\u001b[39m )\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Fit ONLY using training fold\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- Step F: Evaluate on validation fold ---\u001b[39;00m\n\u001b[32m     63\u001b[39m y_pred = gs.predict(X_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:1612\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1611\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:999\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    992\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    995\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    996\u001b[39m         )\n\u001b[32m    997\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1022\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/sklearn/utils/parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Winter/Machine Learning/Project/Code/venv/lib/python3.14/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 7) Run ALL 5 classifiers one-by-one for ONE dataset\n",
    "# =========================\n",
    "\n",
    "dataset_id = 1  # change to 2..16 if you want\n",
    "\n",
    "classifiers = [\"SVM\", \"KNN\", \"DT\", \"RF\", \"MLP\"]\n",
    "\n",
    "phase1_results_data1 = {}\n",
    "\n",
    "for clf_name in classifiers:\n",
    "    print(f\"\\n\\nüîÅ Moving to next classifier: {clf_name}\")\n",
    "    phase1_results_data1[clf_name] = run_phase1_one_classifier(dataset_id, clf_name)\n",
    "\n",
    "print(\"\\n‚úÖ ALL classifiers completed for this dataset.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
